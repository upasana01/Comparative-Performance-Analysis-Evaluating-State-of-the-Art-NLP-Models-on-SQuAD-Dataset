- This project focuses on evaluating the performance of various state-of-the-art natural language processing (NLP) models on the SQuAD dataset. Specifically, we have fine-tuned and assessed the models BERT, RoBERTa, DistilBERT, and T5 to determine their effectiveness in answering questions based on Wikipedia articles.
- SQuAD, short for Stanford Question Answering Dataset, is a well-established benchmark
in the field of natural language processing (NLP). It contains over 100,000
question-answer pairs derived from more than 500 Wikipedia articles. Each question in
the dataset is accompanied by a corresponding answer, which is a specific span of text
within the related article. This structure makes SQuAD an ideal dataset for training and
evaluating question answering systems.
- In our study, we fine-tuned BERT, RoBERTa, DistilBERT, and T5 models on the SQuAD
dataset. We then assessed their performance by comparing their answers to the
reference answers provided in the dataset. Our goal was to measure the effectiveness
of these models in terms of accuracy, F1 score, ROUGE score, and BLEU score.
